# training settings
seed: 6660857
dataset: CIFAR10
strategy: baseline
batch_size: 256
test-batch-size: 50
epochs: 30
optimization: fedprox
mu_loss_prox: 0.1

# DP
enable_privacy: True
noise_multiplier: 1
target_epsilon: 10
target_delta: 0.00001
max_norm: 0.2

# parameters for logging
save-freq: 10
save-model: True
log-interval: 20
save-interval: 100
test-interval: 1

# model settings
arch: ConvNet
lr_net: 1 #update the global model (and client models in dsc settings)
client_settings:
  type: cosine_decay #constant #cosine_decay #multistep #cosine
  #lr: 0.01 # update client models when using the baseline
  lr: 0.1 # update client models when using the baseline
  milestones: [60, 120, 160]
  gamma: 0.2
  T_0: 1
  T_mult: 1
  eta_min: 0.01
  momentum: 0
  weight_decay: 0

# parameter for federated configuration
epoch-client: 5
n-client: 5
n-update-client: 5
shard_per_user: 2
noniid: True